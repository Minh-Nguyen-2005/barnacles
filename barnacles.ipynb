{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f76c3fe",
   "metadata": {},
   "source": [
    "# My Idea: Barnacle Blob Detection with OpenCV + Contour-Based ML (Model-focused)\n",
    "\n",
    "We will build a system that takes a cropped image of a tide pool and returns a count of the barnacles by identifying and filtering shapes based on their visual properties like size and circularity. The final output will be both the total count and a visual overlay showing which objects were identified as barnacles.\n",
    "\n",
    "Use OpenCV to isolate barnacle candidates via blob detection or contours, then train a simple ML classifier (e.g., logistic regression, decision tree) to classify if a blob is a barnacle or not.\n",
    "\n",
    "## Framework\n",
    "\n",
    "1. Use color thresholding to isolate the green frame. Crop the interior region.\n",
    "\n",
    "2. *Image preprocessing* (grayscale, blur, threshold, etc.): Convert the input image into a format that makes it easy to distinguish barnacles from the background.\n",
    "\n",
    "3. *Contour Detection*: Identify all the potential, distinct objects (shapes) in the pre-processed image. Use OpenCV’s findContours() or SimpleBlobDetector to extract shape features.\n",
    "\n",
    "4. *Contour Filtering*: Intelligently filter through all the potential objects to discard things that are not barnacles (e.g., too small, too big, not circular enough). This is the \"ML\" or rule-based intelligence part of the system. From mask1 and mask2, assign labels (1 if contour overlaps mask, 0 otherwise).\n",
    "\n",
    "5. *Counting & Visualization*: Count the final, filtered contours and draw them on the original image to see what the system actually \"counted.\" Train the ML model using features like area, perimeter, circularity, intensity variance.\n",
    "\n",
    "Train on _img1.png_ and _img2.png_. Validate using _unseen_img1.png_ and _unseen_img2.png_. Use _mask1.png_ and _mask2.png_, or _masked_img1.png_ and _masked_img2.png_ for contour detection and counting.\n",
    "\n",
    "## Critical Subtasks\n",
    "\n",
    "* Identify green wire frame and extract the interior region inside its inner square. Here I used:\n",
    "- **Input**: _img1.png_, *Output*: cropped image of inner square region\n",
    "- **Libraries**: OpenCV, NumPy, Math\n",
    "- **Algos**: Color Space Conversion (cv2.cvtColor), Thresholding (cv2.threshold), Morphological Transformations (cv2.morphologyEx), Edge Detection (cv2.Canny), Line Detection (cv2.HoughLinesP), Line Intersection (Custom Algorithm), Line Merging/Clustering (Custom Algorithm), Perspective Transformation (cv2.getPerspectiveTransform, cv2.warpPerspective)\n",
    "\n",
    "* Analyze (by counting and visualizing) the mask contours of barnacles. Here I used:\n",
    "- **Input**: Cropped image of inner square region of _img1.png_, _mask1.png_ or _masked_img1.png_, *Output*: metrics\n",
    "- **Libraries**: OpenCV, NumPy\n",
    "- **Algos**: \n",
    "*Substack 1* - Image Preprocessing: Grayscale Conversion (cv2.cvtColor), Gaussian Blurring (cv2.GaussianBlur), Adaptive Thresholding (cv2.adaptiveThreshold)\n",
    "*Substack 2* - Contour Detection: Finding Contours (cv2.findContours)\n",
    "*Substack 3* - Contour Filtering (The \"Intelligence\"): Contour Area (cv2.contourArea), Contour Perimeter (cv2.arcLength), Circularity Calculation (Custom Algorithm)\n",
    "*Substack 4* - Counting & Visualization: Counting (len()), Drawing Contours (cv2.drawContours), Drawing Text (cv2.putText)\n",
    "\n",
    "## Evaluation:\n",
    "* Subtask 1: Just check the cropped image\n",
    "* Subtask 2:\n",
    "- Count the number of barnacles that the prototype finds in _img1.png_ ```Your_Count```.\n",
    "- Count the number of barnacles in the ground truth _mask1.png_ ```True_Count```.\n",
    "- Accuracy is simply how close ```Your_Count``` is to ```True_Count```. For example, ```(Your_Count / True_Count) * 100%```.\n",
    "- Visual overlay to see false positives/negatives.\n",
    "\n",
    "## Things I learned:\n",
    "\n",
    "Even though I have not taken the 70's in CS, thanks to this challenge, I applied for financial aid on Coursera and learned the Supervised Machine Learning: Regression and Classification course. I have also research a lot for the first time regarding OpenCV."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db7793fb",
   "metadata": {},
   "source": [
    "### Import Libraries and Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4d43d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "from barnacles_counter.barnacles_crop import debug_crop, crop_to_inner_frame_hsv, crop_to_inner_frame_canny, crop_to_inner_frame, crop_inner_square\n",
    "from barnacles_counter.barnacles_analyze import analyze_and_count_barnacles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b3e86f0",
   "metadata": {},
   "source": [
    "### Subtask 1: Detect green frame and crop the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb4820e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Still failed at cropping but was successful at detecting green frame\n",
    "input_image_file = 'data/img1.png' \n",
    "crop_inner_square(input_image_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f850cf",
   "metadata": {},
   "source": [
    "### Subtask 2: Analyze mask contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1842478d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the prototype on the mask1 image\n",
    "# Use the photographic image as input for the analyzer.\n",
    "input_image_path = \"data/mask1.png\"\n",
    "detected_count, result_image = analyze_and_count_barnacles(input_image_path)\n",
    "\n",
    "# Display the result\n",
    "if result_image is not None:\n",
    "    print(f\"Prototype detected {detected_count} barnacles.\")\n",
    "    cv2.imwrite(\"prototype_output_img1.png\", result_image)\n",
    "\n",
    "# Run the prototype on the masked_img1 image\n",
    "input_image_path2 = \"data/masked_img1.png\"\n",
    "detected_count2, result_image2 = analyze_and_count_barnacles(input_image_path2)\n",
    "\n",
    "# Display the result\n",
    "if result_image is not None:\n",
    "    print(f\"Prototype detected {detected_count2} barnacles.\")\n",
    "    cv2.imwrite(\"prototype_output_img2.png\", result_image2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc1d6edb",
   "metadata": {},
   "source": [
    "### My failed attempt on Subtask 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e3b8e6",
   "metadata": {},
   "source": [
    "Regenerate _img1.png_ using Matplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4554a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('data/img1.png')\n",
    "img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(img_rgb) \n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7b42fa8",
   "metadata": {},
   "source": [
    "Regenerate masked_img1.png using Matplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b738a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the “pretty” masked overlay\n",
    "masked_overlay = cv2.imread('data/masked_img1.png')\n",
    "# It’s BGR with the barnacle contours already in a color (likely red).\n",
    "# Convert to RGB for Matplotlib:\n",
    "masked_overlay_rgb = cv2.cvtColor(masked_overlay, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.imshow(masked_overlay_rgb)\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a32c35",
   "metadata": {},
   "source": [
    "Crop green frame using OpenCV's HSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "568e25d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "crop = crop_to_inner_frame_hsv(img, debug=True)\n",
    "if crop is None:\n",
    "    print(\"Frame not detected—tweak HSV bounds or area threshold.\")\n",
    "else:\n",
    "    plt.figure(figsize=(6,6))\n",
    "    plt.imshow(crop)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d7aa0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load\n",
    "hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "# tweak these coordinates until you hit a green wire\n",
    "y, x = 100, 200  \n",
    "print(\"Sample HSV at (x=200,y=100):\", hsv[y, x])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee485cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# green thresholds\n",
    "lower_green = np.array([40, 40, 40])\n",
    "upper_green = np.array([70, 255, 255])\n",
    "\n",
    "# Build the mask\n",
    "green_mask = cv2.inRange(hsv, lower_green, upper_green)\n",
    "\n",
    "# Show the mask\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.imshow(green_mask, cmap='gray')\n",
    "plt.title(\"Green‐frame mask\")\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "# Clean it up a bit\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (7,7))\n",
    "mask_clean = cv2.morphologyEx(green_mask, cv2.MORPH_OPEN,  kernel)\n",
    "mask_clean = cv2.morphologyEx(mask_clean,  cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.imshow(mask_clean, cmap='gray')\n",
    "plt.title(\"After open + close\")\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "# Quick contour check\n",
    "cnts, _ = cv2.findContours(mask_clean, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "print(\"Contours found:\", len(cnts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a335ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "debug_crop(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7361321",
   "metadata": {},
   "source": [
    "Crop green frame using OpenCV's HSV and Canny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d62b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the cropping pipeline\n",
    "cropped = crop_to_inner_frame(img, debug=True)\n",
    "\n",
    "if cropped is None:\n",
    "    print(\"Frame not detected—tweak thresholds or area cutoff.\")\n",
    "else:\n",
    "    plt.figure(figsize=(6,6))\n",
    "    plt.imshow(cropped)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c05eb62",
   "metadata": {},
   "source": [
    "Crop green frame using OpenCV's Canny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41cd47b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the edge-based crop with debug windows\n",
    "cropped_edge = crop_to_inner_frame_canny(img, debug=True)\n",
    "\n",
    "if cropped_edge is None:\n",
    "    print(\"Frame not found—tweak Canny thresholds or kernel size.\")\n",
    "else:\n",
    "    # Display the final cropped RGB image inline\n",
    "    plt.figure(figsize=(6,6))\n",
    "    plt.imshow(cropped_edge)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
